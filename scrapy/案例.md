# 一、Scrapy入门教程
## <h1>Darwin - The Evolution Of An Exhibition</h1>
对应的xpath表达式：
//h1/text()

## <h2>Description:</h2>
<div id="description">
Short documentary made for Plymouth City Museum and Art Gallery regarding the setup of an exhibit about Charles Darwin in conjunction with the 200th anniversary of his birth.
...
对应的xpath表达式：
//div[@id='description']

## <div id="specifications">
<p>
<strong>Category:</strong>
<a href="/cat/4">Movies</a> &gt; <a href="/sub/35">Documentary</a>
</p>
<p>
<strong>Total size:</strong>
150.62&nbsp;megabyte</p>
对应的xpath表达式：
//div[@id='specifications']/p[2]/text()[2]

## spider主要代码：
torrent = TorrentItem()
torrent['url'] = response.url
torrent['name'] = response.xpath("//h1/text()").extract()
torrent['description'] = response.xpath("//div[@id='description']").extract()
torrent['size'] = response.xpath("//div[@id='info-left']/p[2]/text()[2]").extract()
return torrent

## 我们可以运行spider来获取网站的数据，并以JSON格式存入到 scraped_data.json 文件中:
scrapy crawl mininova -o scraped_data.json

### 项目一：
https://scrapy-chs.readthedocs.io/zh_CN/latest/intro/tutorial.html
1、创建一个Scrapy项目，名为tutorial
scrapy startproject tutorial
    scrapy.cfg: 项目的配置文件
    tutorial/: 该项目的python模块。之后您将在此加入代码。
    tutorial/items.py: 项目中的item文件.
    tutorial/pipelines.py: 项目中的pipelines文件.
    tutorial/settings.py: 项目的设置文件.
    tutorial/spiders/: 放置spider代码的目录.
2、定义提取的Item
3、编写爬取网站的 spider 并提取 Item
4、编写 Item Pipeline 来存储提取到的Item(即数据)

--执行代码scrapy crawl fanyi    （fanyi为spider目录下自创文件中的name值）

### 项目二：
1、创建一个Scrapy项目，名为quotesbot

